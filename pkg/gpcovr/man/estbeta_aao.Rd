% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcmc_funcs_aao_batch.R
\name{estbeta_aao}
\alias{estbeta_aao}
\title{Estimate spline coefficients}
\usage{
estbeta_aao(filename, errname, nbatch, batchidx, H, Y, B, last_few_beta,
  last_few_tau, prev_lik, last_accept, knots, sigma.m, v_tau, t_v,
  r.opt = 0.23, eps, nugget = 0.001, errthin = 100)
}
\arguments{
\item{filename}{Name of the file to store the betas in}

\item{errname}{Name of the file to store the covariance functions in}

\item{nbatch}{Number of iterations to run this function for. See "Details"}

\item{batchidx}{Index of the current batch}

\item{H}{The distance matrix between the observations. \code{M} x \code{M}
matrix, where \code{M} is the number of observations.}

\item{Y}{The vector of observations. Length \code{M}}

\item{B}{The number of random draws to take from the spline-approximated
spectral density}

\item{last_few_beta}{Last \code{r} values for the spline coefficients}

\item{last_few_tau}{Last \code{r} for the variance scalar}

\item{prev_lik}{The most recent likelihood value}

\item{last_accept}{Whether \code{prev_lik} was accepted or not}

\item{knots}{The vector of knot locations}

\item{sigma.m}{The \code{beta} proposal variance hyperparameter}

\item{v_tau}{The \code{tau} proposal variance hyperparameter}

\item{t_v}{The prior variance hyperparameter (not being adapted)}

\item{r.opt}{The optimal acceptance rate (used for adaptive tuning)}

\item{eps}{Not used I think}

\item{nugget}{Nugget effect}

\item{errthin}{Thinning parameter for calculating error bounds. E.g. if
\code{errthin} = 100, every 100th sample will be written out to the error
file}
}
\value{
Returns a list of information to pass to \code{\link{estbeta_aao}}. Also
  writes output to some csv files.
}
\description{
This and \code{\link{estbeta_aao_initialize}} probably should not be two separate
functions but oh well. This function contains the main MCMC loop.
}
\details{
If \code{nbatch} is too big, the program will crash eventually
  because R is dumb and won't release the memory after each expensive
  likelihood calculation. A value of around 100 is recommended.
}
